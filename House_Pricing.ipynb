{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1VwLwTInYGr"
   },
   "source": [
    "# Discover ML with Ames, Ioha House pricing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6F8EuUUXdIF"
   },
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuxoK5ZBX4T4"
   },
   "source": [
    "Importing base python libraries we will use throughout the workshop + base configuration for the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HCTExE4ofYC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpAm1o1CYFIA"
   },
   "source": [
    "For this workshop we will only work on a subset of the available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CZzmxcxrQyh"
   },
   "outputs": [],
   "source": [
    "selected_features=[\n",
    "    'SalePrice',\n",
    "    'LotArea', \n",
    "    'Neighborhood', \n",
    "    'HouseStyle', \n",
    "    'OverallQual', \n",
    "    'KitchenQual',\n",
    "    'OverallCond', \n",
    "    'YearBuilt', \n",
    "    'Foundation', \n",
    "    'Heating', \n",
    "    'CentralAir', \n",
    "    'GrLivArea', \n",
    "    'GarageCars',\n",
    "    'PoolArea'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JltNCu7zYNqh"
   },
   "source": [
    "Importing the data from an online repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zymMpccbqCDn"
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('https://raw.githubusercontent.com/cloderic/ml_intro/master/data/house_prices/data.csv', index_col='Id')\n",
    "df = full_df[selected_features]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Txf8SKvkZoWQ"
   },
   "source": [
    "Counting the number of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaDjnLm3Zlsc"
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SV-YuZSXYR6l"
   },
   "source": [
    "Importing some feature metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZ9Sy6nEUQGX"
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.read_json('https://raw.githubusercontent.com/cloderic/ml_intro/master/data/house_prices/data_description.json')\n",
    "metadata_df = metadata_df.loc[metadata_df['feature'].isin(selected_features)].set_index('feature')\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtPFqtnOLjnY"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical & categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDvETl3hYnpt"
   },
   "outputs": [],
   "source": [
    "numerical_features = list(df._get_numeric_data().columns)\n",
    "categorical_features = list(set(df.columns) - set(numerical_features))\n",
    "print('categorical features', categorical_features)\n",
    "print('numerical features', numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jy9N91P8ZYDt"
   },
   "outputs": [],
   "source": [
    "def describe_feature(df, feature):\n",
    "    description = df[feature].describe()\n",
    "    print('feature: \\t\\t', feature)\n",
    "    if (feature in metadata_df['description']):\n",
    "        print('description: \\t\\t', metadata_df['description'][feature])\n",
    "    print('# records: \\t\\t', description['count'])\n",
    "    print('# null records: \\t', df[feature].isnull().sum())\n",
    "    if 'unique' in description:\n",
    "        # It's a categorical feature\n",
    "        print('# values: \\t\\t', description['unique'])\n",
    "        values_count=df[feature].value_counts()\n",
    "        print('values:')\n",
    "        for value in values_count.index:\n",
    "            print('  - value: \\t\\t', value)\n",
    "            print('    description: \\t', metadata_df['values'][feature][value])\n",
    "            print('    # records: \\t\\t', values_count[value])\n",
    "    else:\n",
    "        # It's a numerical feature\n",
    "        print('average: \\t\\t', description['mean'])\n",
    "        print('standard deviation: \\t', description['std'])\n",
    "        print('min: \\t\\t\\t', description['min'])\n",
    "        print('1st quartile: \\t\\t', description['25%'])\n",
    "        print('median: \\t\\t', description['50%'])\n",
    "        print('3rd quartile: \\t\\t', description['75%'])\n",
    "        print('max: \\t\\t\\t', description['max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `describe_feature` function to explore the features, categorical or numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jy9N91P8ZYDt"
   },
   "outputs": [],
   "source": [
    "describe_feature(df, 'Foundation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feature(df, 'OverallCond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tozBpHbQLtQV"
   },
   "source": [
    "### Price distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHG0YdTJsHtt"
   },
   "outputs": [],
   "source": [
    "# Setup Seaborn style\n",
    "sns.set(rc={'figure.figsize':(18,12)})\n",
    "\n",
    "sns.distplot(df['SalePrice']);\n",
    "#sns.distplot(df[df['Neighborhood']=='NridgHt']['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEzgcz9Lms7d"
   },
   "outputs": [],
   "source": [
    "df_g_neighborhood = df.groupby(by='Neighborhood')\n",
    "df_g_neighborhood['SalePrice'].describe().sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUTwetqBe56B"
   },
   "outputs": [],
   "source": [
    "def plot_neighborhood_distributions(df, column):\n",
    "    for neighborhood, df_neighborhood in df.groupby(by='Neighborhood'):\n",
    "        sns.distplot(df_neighborhood[column], hist=False, rug=False, label=metadata_df['values']['Neighborhood'][neighborhood] + ' (' + neighborhood + ')')\n",
    "    \n",
    "plot_neighborhood_distributions(df, 'SalePrice')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yM-ox4nHzn1e"
   },
   "source": [
    "### Relationship with other numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0Whnloy0Qd2"
   },
   "outputs": [],
   "source": [
    "corrmat = df.corr()\n",
    "sns.heatmap(corrmat, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCKZfD9uMdV0"
   },
   "outputs": [],
   "source": [
    "correlations_df = pd.DataFrame({ 'correlation': corrmat['SalePrice'] })\n",
    "correlations_df = pd.merge(correlations_df, metadata_df[['description']], how='left', left_index=True, right_index=True)\n",
    "correlations_df['abs_correlation'] = abs(correlations_df['correlation'])\n",
    "correlations_df = correlations_df.sort_values('abs_correlation', ascending=False)\n",
    "correlations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYT1SO-oMLLM"
   },
   "source": [
    "#### Price vs Living Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UvkSjjpyQdH"
   },
   "outputs": [],
   "source": [
    "def plot_2d(x_feature, y_feature):\n",
    "  data = pd.concat([df[x_feature], df[y_feature], ], axis=1)\n",
    "  data.plot.scatter(x=x_feature, y=y_feature)\n",
    "\n",
    "plot_2d('GrLivArea', 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEIlN34ZpdNo"
   },
   "source": [
    "#### Price vs Pool area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxLiTqe2pjJk"
   },
   "outputs": [],
   "source": [
    "plot_2d('PoolArea', 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujaWAi3gMSC2"
   },
   "source": [
    "#### Price vs Overall Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyc1EvXt2XzJ"
   },
   "source": [
    "![Box plot explanation](https://upload.wikimedia.org/wikipedia/commons/1/1a/Boxplot_vs_PDF.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbeO9snH0GTQ"
   },
   "outputs": [],
   "source": [
    "def plot_box2d(x_feature, y_feature):\n",
    "  data = pd.concat([df[x_feature], df[y_feature], ], axis=1)\n",
    "  sns.boxplot(x=x_feature, y=y_feature, data=data)\n",
    "\n",
    "plot_box2d('OverallQual', 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMV0SRlQz_Lo"
   },
   "source": [
    "#### Price vs Overall condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3jCQse_zhq9"
   },
   "outputs": [],
   "source": [
    "plot_box2d('OverallCond', 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OverallCond vs Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box2d('Neighborhood', 'OverallQual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8d3oLYpLRUo"
   },
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAgboEFpK9nt"
   },
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Qt2h8glN8Lq"
   },
   "outputs": [],
   "source": [
    "describe_feature(df, 'CentralAir')\n",
    "print('------------')\n",
    "describe_feature(df, 'KitchenQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHTR5JUQwCH-"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "def target_encoder(df, encoded_feature, target_feature):\n",
    "    df_te = pd.DataFrame()\n",
    "    df_te = df_te.append(df.groupby(encoded_feature)[target_feature].agg(['mean']).reset_index())\n",
    "    df_te.rename(columns={'mean': 'TargetEncoded{}Mean{}'.format(target_feature,encoded_feature)},\n",
    "                 inplace=True)\n",
    "    df = pd.merge(df, df_te, how='left').set_index(df.index)\n",
    "    return df\n",
    "\n",
    "def encode_categorical_features(df, onehot_encoded_features=[], ordinal_encoded_features={}, target_encoded_features={}):\n",
    "    # One hot encoding\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "    onehot_encoder.fit(df[onehot_encoded_features])\n",
    "    encoded_df = pd.concat([df,\n",
    "                            pd.DataFrame(\n",
    "                                data=onehot_encoder.transform(df[onehot_encoded_features]), \n",
    "                                columns=onehot_encoder.get_feature_names(onehot_encoded_features), \n",
    "                                index=df.index)\n",
    "                           ], axis=1)\n",
    "    \n",
    "\n",
    "    # Create the ordinal encoder\n",
    "    ordinal_encoded_features_keys = [key for key in ordinal_encoded_features.keys()] \n",
    "    ordinal_encoded_features_values = [value for value in ordinal_encoded_features.values()]\n",
    "    ordinal_encoded_features_output = ['Encoded{}'.format(key) for key in ordinal_encoded_features_keys]\n",
    "    ordinal_encoder = OrdinalEncoder(ordinal_encoded_features_values)\n",
    "    ordinal_encoder.fit(df[ordinal_encoded_features_keys])\n",
    "    encoded_df = pd.concat([encoded_df,\n",
    "                            pd.DataFrame(\n",
    "                                data=ordinal_encoder.transform(df[ordinal_encoded_features_keys]), \n",
    "                                columns=ordinal_encoded_features_output, index=df.index)\n",
    "                           ], axis=1)\n",
    "    \n",
    "    target_encoded_features_keys = [key for key in target_encoded_features.keys()] \n",
    "    for encoded_feature in target_encoded_features_keys:\n",
    "        encoded_df = target_encoder(df=encoded_df, encoded_feature=encoded_feature, target_feature=target_encoded_features[encoded_feature])\n",
    "    \n",
    "    # Drop the encoded features\n",
    "    encoded_df = encoded_df.drop(onehot_encoded_features, axis=1, errors='ignore')\n",
    "    encoded_df = encoded_df.drop(ordinal_encoded_features_keys, axis=1, errors='ignore')\n",
    "    encoded_df = encoded_df.drop(target_encoded_features_keys, axis=1, errors='ignore')\n",
    "    return encoded_df\n",
    "    \n",
    "encoded_df = encode_categorical_features(\n",
    "    df,\n",
    "    onehot_encoded_features=['CentralAir','HouseStyle','Foundation','Heating', 'Neighborhood'], \n",
    "    ordinal_encoded_features={'KitchenQual':['Po', 'TA', 'Fa', 'Gd', 'Ex']},\n",
    "    #target_encoded_features={'Neighborhood': 'SalePrice'}\n",
    ")\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1oBlHW-WjoJ"
   },
   "source": [
    "### Update the correlation matrix with the encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diZ4g7eLw9u_"
   },
   "outputs": [],
   "source": [
    "corrmat = encoded_df.corr()\n",
    "sns.heatmap(corrmat, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7yQHBU8Woox"
   },
   "outputs": [],
   "source": [
    "correlations_df = pd.DataFrame({ 'correlation': corrmat['SalePrice'] })\n",
    "correlations_df['abs_correlation'] = abs(correlations_df['correlation'])\n",
    "correlations_df = correlations_df.sort_values('abs_correlation', ascending=False)\n",
    "correlations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvpfpzG7XfvN"
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFortltoXl32"
   },
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWEBq45yXirG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 'SalePrice'\n",
    "ignored_features = ['OverallCond']\n",
    "features = list(set(encoded_df.columns) - set(['SalePrice']) - set(['OverallCond']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input values can be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalized_encoded_df = encoded_df.copy()\n",
    "features_normalizer = StandardScaler()\n",
    "normalized_encoded_df[features] = features_normalizer.fit_transform(encoded_df[features])\n",
    "target_normalizer = StandardScaler()\n",
    "normalized_encoded_df[[target]] = target_normalizer.fit_transform(encoded_df[[target]])\n",
    "normalized_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBvvka0NYuRK"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(encoded_df, test_size=0.3, random_state=666)\n",
    "train_normalized_df, test_normalized_df = train_test_split(normalized_encoded_df, test_size=0.3, random_state=666)\n",
    "train_results_df = train_df[[target]].rename(columns={target: 'Truth'})\n",
    "test_results_df = test_df[[target]].rename(columns={target: 'Truth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_gCHNe9Y6w7"
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_df['SalePrice'], hist=False, rug=False, label='train')\n",
    "sns.distplot(test_df['SalePrice'], hist=False, rug=False, label='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlgtheI4ooQW"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5yIvHMHZEj9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_results(results):\n",
    "  sns.lineplot(data=results.sort_values('Truth').reset_index().drop(columns=['Id']))\n",
    "  \n",
    "def compute_scores(method, results):\n",
    "  return pd.Series(\n",
    "    data=[mean_absolute_error(results['Truth'], results[method]), \n",
    "          r2_score(results['Truth'], results[method])],\n",
    "    index=['mae ($)', 'r2'],\n",
    "    name=method)\n",
    "\n",
    "def update_results(method, trained_regressor, df, result_df, trained_scaler = None):\n",
    "    if trained_scaler:\n",
    "        result_df[method] = trained_scaler.inverse_transform(trained_regressor.predict(df[features]))\n",
    "    else:\n",
    "        result_df[method] = trained_regressor.predict(df[features])\n",
    "    \n",
    "    plot_results(result_df)\n",
    "\n",
    "    return pd.DataFrame([compute_scores(method, result_df) for method in list(set(result_df.columns) - set(['Truth']))])\n",
    "\n",
    "lin_regressor = LinearRegression(fit_intercept=False).fit(train_df[features], train_df[[target]])\n",
    "update_results('Simple Linear Regression', lin_regressor, train_df, train_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gl_0C57wotCl"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QceYG9zAZ_FB"
   },
   "outputs": [],
   "source": [
    "update_results('Simple Linear Regression', lin_regressor, test_df, test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the largest errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_error_df = (test_results_df\n",
    "                  .assign(absolute_error=lambda df: abs(df['Truth'] - df['Simple Linear Regression']))\n",
    "                  .sort_values('absolute_error', ascending=False)\n",
    "                  .head())\n",
    "worse_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.isin(worse_error_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQvx6GQ3o0nd"
   },
   "source": [
    "### Understanding the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ6JThthb0im"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=lin_regressor.coef_[0], columns=['coef'], index=features).sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlgtheI4ooQW"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5yIvHMHZEj9"
   },
   "outputs": [],
   "source": [
    "normalized_lin_regressor = LinearRegression(fit_intercept=False).fit(train_normalized_df[features], train_normalized_df[[target]])\n",
    " \n",
    "update_results('Normalized Linear Regression', normalized_lin_regressor, train_normalized_df, train_results_df, target_normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gl_0C57wotCl"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QceYG9zAZ_FB"
   },
   "outputs": [],
   "source": [
    "update_results('Normalized Linear Regression', normalized_lin_regressor, test_normalized_df, test_results_df, target_normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQvx6GQ3o0nd"
   },
   "source": [
    "### Understanding the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ6JThthb0im"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=normalized_lin_regressor.coef_[0], columns=['coef'], index=features).sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "309j-4huDORB"
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfhPkZDuuZdH"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor(max_depth=10).fit(train_df[features], train_df[[target]])\n",
    "update_results('Decision Tree', dt_regressor, train_df, train_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPXAC9mWDXtO"
   },
   "outputs": [],
   "source": [
    "update_results('Decision Tree', dt_regressor, test_df, test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "def plot_dt(dt, max_depth):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(dt, \n",
    "                    out_file=dot_data,  \n",
    "                    filled=True, \n",
    "                    rounded=True,\n",
    "                    feature_names=features,\n",
    "                    max_depth=max_depth,\n",
    "                    special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    return Image(graph.create_png())\n",
    "    \n",
    "plot_dt(dt_regressor, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTPz9uO8pPzM"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UWlYudS4pZtF"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsG3oceUpUj2"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Creating a validation set \n",
    "train_nn_df, validate_nn_df = train_test_split(train_normalized_df, test_size=0.1, random_state=666)\n",
    "\n",
    "nn_regressor = Sequential([\n",
    "    Dense(8, name='hidden', activation='relu', input_shape=(len(features),)),\n",
    "    Dense(1, name='output', activation='sigmoid', use_bias=False),\n",
    "])\n",
    "\n",
    "nn_regressor.compile(optimizer='sgd',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mae'])\n",
    "\n",
    "nn_regressor.fit(train_nn_df[features], train_nn_df[[target]],\n",
    "                 batch_size=32, epochs=100,\n",
    "                 validation_data=(validate_nn_df[features], validate_nn_df[[target]]))\n",
    "\n",
    "update_results('Neural Network', nn_regressor, train_normalized_df, train_results_df, target_normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzMta6wVpxgb"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyDmUzTjpqmg"
   },
   "outputs": [],
   "source": [
    "update_results('Neural Network', nn_regressor, test_normalized_df, test_results_df, target_normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBfXUg8-uSiH"
   },
   "source": [
    "### Understanding the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQaQHphRuR7l"
   },
   "outputs": [],
   "source": [
    "nn_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_regressor.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor().fit(train_df[features], train_df[[target]])\n",
    "update_results('Random Forest', rf_regressor, train_df, train_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_results('Random Forest', rf_regressor, test_df, test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=rf_regressor.feature_importances_, columns=['feature_importance'], index=features).sort_values('feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dt(rf_regressor[0], max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[ML Intro] House Pricing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
